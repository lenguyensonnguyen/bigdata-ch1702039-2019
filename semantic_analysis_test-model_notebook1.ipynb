{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <p>\n",
    "        MÔN BIG DATA 2019\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Nhóm 13 - Le Nguyen Son Nguyen - CH1702039\n",
    "    </p>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    <p>\n",
    "        SỬ DỤNG SPARK VÀ SPARK MACHINE LEARNING LIBRARY ĐỂ TRAIN MODEL PHÂN TÍCH NGỮ NGHĨA DÙNG MULTILAYER PERCEPTRONS (BASIC DEEP LEARNING)\n",
    "    </p>\n",
    "    <p style=\"color: blue\">\n",
    "        Phần đánh giá (Evaluation) Model đã train\n",
    "    </p>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo các biến môi trường để Spark sử dụng trong quá trình chạy\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:30:05.891407Z",
     "start_time": "2019-11-11T07:30:05.872735Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/spark/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color: blue\">\n",
    "        Dùng gói findSpark để khởi tạo môi trường chạy\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:30:13.399900Z",
     "start_time": "2019-11-11T07:30:13.329432Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Import các thư viện của PySpark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:30:22.556048Z",
     "start_time": "2019-11-11T07:30:20.651068Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo số memory mà mỗi Worker sẽ sử dụng để thực thi task\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:30:52.703507Z",
     "start_time": "2019-11-11T07:30:27.612362Z"
    }
   },
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '6656m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo địa chỉ của Spark master, lưu ý là phải thay đổi địa chỉ cho phù hợp với từng Spark cluster\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:42:53.899269Z",
     "start_time": "2019-11-11T07:42:34.068615Z"
    }
   },
   "outputs": [],
   "source": [
    "# tạo spark context, lưu ý nhớ thay đổi lại địa chỉ của spark cho phù hợp\n",
    "sc = SparkContext(\"spark://10.255.255.6:7077\", \"Sematic Analysic Evaluation\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:43:39.667099Z",
     "start_time": "2019-11-11T07:43:39.648157Z"
    }
   },
   "outputs": [],
   "source": [
    "# khai báo một số hằng số\n",
    "NUMBER_INSTANCE_FOR_PC = 12500\n",
    "# NUMBER_FEATURE_VECTOR = 500\n",
    "# đường dẫn đến tập train positive\n",
    "TEST_PATH_POS = \"./semantic_data/aclImdb/test/pos/\"\n",
    "# đường dẫn đến tập train negative\n",
    "TEST_PATH_NEG = \"./semantic_data/aclImdb/test/neg/\"\n",
    "# biến lưu dữ liệu train cả positive và negative\n",
    "data_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Dữ liệu test cũng có 2 tập:\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Positive: nhận xét tích cực, chứa các câu nhận xét mang ý nghĩa tích cực, sẽ được đánh label là 1\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Negative: nhận xét tiêu cực, chứa các câu nhận xét mang ý nghĩa tiêu cực, sẽ được đánh label là 0\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:44:27.249724Z",
     "start_time": "2019-11-11T07:43:46.584940Z"
    }
   },
   "outputs": [],
   "source": [
    "# đọc dữ liệu của data train positive\n",
    "listfile_pos = listdir(TEST_PATH_POS)\n",
    "listfile_pos = enumerate(listfile_pos)\n",
    "counter = 1\n",
    "for index, file_pos in listfile_pos:\n",
    "    try:\n",
    "        with open(TEST_PATH_POS + file_pos, 'r') as f_pos:\n",
    "            noidung = f_pos.read()\n",
    "            noidung = noidung.lower()\n",
    "            # đánh label cho tập data train positive là 1\n",
    "            data_test.append((index, noidung, 1))\n",
    "        if counter >= NUMBER_INSTANCE_FOR_PC:\n",
    "            break\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:46:18.382634Z",
     "start_time": "2019-11-11T07:45:40.313664Z"
    }
   },
   "outputs": [],
   "source": [
    "# lấy dữ liệu cho tập data train negative\n",
    "listfile_neg = listdir(TEST_PATH_NEG)\n",
    "listfile_neg = enumerate(listfile_neg)\n",
    "counter = 1\n",
    "for index, file_neg in listfile_neg:\n",
    "    try:\n",
    "        with open(TEST_PATH_NEG + file_neg) as f_neg:\n",
    "            noidung_neg = f_neg.read()\n",
    "            noidung_neg = noidung_neg.lower()\n",
    "            # đánh label cho data train negative là 0\n",
    "            data_test.append((index, noidung_neg, 0))\n",
    "            if counter >= NUMBER_INSTANCE_FOR_PC:\n",
    "                break\n",
    "            else:\n",
    "                counter = counter + 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Tạo đối tượng DataFrame trong Spark để chứa dữ liệu train, đây là kiểu dữ liệu chuẩn trong việc xử lý phân tán và có thể thao tác dưới dạng SQL, lúc này dữ liệu train đã ở dạng phân tán khắp cluster\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:47:47.456811Z",
     "start_time": "2019-11-11T07:47:15.165506Z"
    }
   },
   "outputs": [],
   "source": [
    "# tạo DataFrame trong Spark\n",
    "sentenceDataFrame_test = spark.createDataFrame(data_test, [\"id\", \"sentence\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "      Sử dụng lại model đã lưu thì dùng lệnh dưới đây\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:52:25.520113Z",
     "start_time": "2019-11-11T07:52:25.330549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, sentence: string, label: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceDataFrame_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:54:07.514378Z",
     "start_time": "2019-11-11T07:53:52.259657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+\n",
      "| id|            sentence|label|\n",
      "+---+--------------------+-----+\n",
      "|  0|nothing really un...|    1|\n",
      "|  1|i saw this movie ...|    1|\n",
      "|  2|sharpe's honour f...|    1|\n",
      "|  3|words can hardly ...|    1|\n",
      "|  4|this small john f...|    1|\n",
      "|  5|this film screene...|    1|\n",
      "|  6|ghillie a remake ...|    1|\n",
      "|  7|this is the best ...|    1|\n",
      "|  8|i really enjoyed ...|    1|\n",
      "|  9|the last film tha...|    1|\n",
      "| 10|featuring some am...|    1|\n",
      "| 11|this isn't a life...|    1|\n",
      "| 12|i thought this mo...|    1|\n",
      "| 13|this movie stands...|    1|\n",
      "| 14|i was impressed w...|    1|\n",
      "| 15|i consider myself...|    1|\n",
      "| 16|rita hayworth as ...|    1|\n",
      "| 17|i had the good fo...|    1|\n",
      "| 18|i loved this film...|    1|\n",
      "| 19|people who say th...|    1|\n",
      "| 20|this may be the m...|    1|\n",
      "| 21|i never saw docto...|    1|\n",
      "| 22|hilarious show wi...|    1|\n",
      "| 23|in following the ...|    1|\n",
      "| 24|good movie, actin...|    1|\n",
      "| 25|what makes this o...|    1|\n",
      "| 26|writer/director j...|    1|\n",
      "| 27|kon ichikawa had ...|    1|\n",
      "| 28|i loved this movi...|    1|\n",
      "| 29|having watched th...|    1|\n",
      "| 30|i am profoundly g...|    1|\n",
      "| 31|this second pairi...|    1|\n",
      "| 32|who won the best ...|    1|\n",
      "| 33|each guy liv tyle...|    1|\n",
      "| 34|there was talk on...|    1|\n",
      "| 35|pretty amusing sp...|    1|\n",
      "| 36|when i was younge...|    1|\n",
      "| 37|well groomed, wel...|    1|\n",
      "| 38|this is film is p...|    1|\n",
      "| 39|a wounded tonto s...|    1|\n",
      "| 40|everyone is a gen...|    1|\n",
      "| 41|this show was inc...|    1|\n",
      "| 42|the best british ...|    1|\n",
      "| 43|being of cephallo...|    1|\n",
      "| 44|many films attemp...|    1|\n",
      "| 45|out to sea was a ...|    1|\n",
      "| 46|isabel has just g...|    1|\n",
      "| 47|b.b. thornton pro...|    1|\n",
      "| 48|i just discovered...|    1|\n",
      "| 49|i just checked ou...|    1|\n",
      "+---+--------------------+-----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceDataFrame_test.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:56:04.938878Z",
     "start_time": "2019-11-11T07:54:56.388407Z"
    }
   },
   "outputs": [],
   "source": [
    "pl_model = PipelineModel.load(\"hdfs://s14e18f4e58324b66b78ecd8c831a0c6413-master.uitlab.com:9000/sparkdata/pl2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "      Dùng model đã train áp dụng (transform) lên dữ liệu test đã tạo\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:58:53.901580Z",
     "start_time": "2019-11-11T07:58:45.596516Z"
    }
   },
   "outputs": [],
   "source": [
    "data_after_transform = pl_model.transform(sentenceDataFrame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T07:59:52.284189Z",
     "start_time": "2019-11-11T07:59:36.199153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| id|            sentence|label|           words_raw|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0|nothing really un...|    1|[nothing, really,...|[nothing, really,...|(500,[3,14,15,18,...|(500,[3,14,15,18,...|[-1.1581063945789...|[0.20211904987504...|       1.0|\n",
      "|  1|i saw this movie ...|    1|[i, saw, this, mo...|[saw, movie, last...|(500,[3,5,6,40,45...|(500,[3,5,6,40,45...|[0.71244190024558...|[0.90394193650352...|       0.0|\n",
      "|  2|sharpe's honour f...|    1|[sharpe's, honour...|[sharpe's, honour...|(500,[1,3,4,6,7,8...|(500,[1,3,4,6,7,8...|[0.91740188965713...|[0.93571410234343...|       0.0|\n",
      "|  3|words can hardly ...|    1|[words, can, hard...|[words, hardly, d...|(500,[41,44,58,85...|(500,[41,44,58,85...|[0.16285030023818...|[0.80065044019937...|       0.0|\n",
      "|  4|this small john f...|    1|[this, small, joh...|[small, john, for...|(500,[3,4,8,11,12...|(500,[3,4,8,11,12...|[-0.0706616244682...|[0.67000709485370...|       0.0|\n",
      "|  5|this film screene...|    1|[this, film, scre...|[film, screened, ...|(500,[3,7,16,19,3...|(500,[3,7,16,19,3...|[-0.8161750340510...|[0.34810623865947...|       1.0|\n",
      "|  6|ghillie a remake ...|    1|[ghillie, a, rema...|[ghillie, remake,...|(500,[4,7,8,9,10,...|(500,[4,7,8,9,10,...|[-1.1560581527553...|[0.20618863929003...|       1.0|\n",
      "|  7|this is the best ...|    1|[this, is, the, b...|[best, 3-d, exper...|(500,[3,11,18,31,...|(500,[3,11,18,31,...|[1.14236970179998...|[0.95836745411326...|       0.0|\n",
      "|  8|i really enjoyed ...|    1|[i, really, enjoy...|[really, enjoyed,...|(500,[32,44,123,1...|(500,[32,44,123,1...|[-0.8698023195619...|[0.32509469644305...|       1.0|\n",
      "|  9|the last film tha...|    1|[the, last, film,...|[last, film, prov...|(500,[0,1,3,6,10,...|(500,[0,1,3,6,10,...|[-3.5689621812159...|[0.00214699102465...|       1.0|\n",
      "| 10|featuring some am...|    1|[featuring, some,...|[featuring, amazi...|(500,[3,9,12,25,3...|(500,[3,9,12,25,3...|[-2.4885217329636...|[0.02091747405615...|       1.0|\n",
      "| 11|this isn't a life...|    1|[this, isn't, a, ...|[life-changing, m...|(500,[3,7,48,92,9...|(500,[3,7,48,92,9...|[-0.7806835076399...|[0.33341403038889...|       1.0|\n",
      "| 12|i thought this mo...|    1|[i, thought, this...|[thought, movie, ...|(500,[3,5,15,17,2...|(500,[3,5,15,17,2...|[-3.1491880438612...|[0.00443802251426...|       1.0|\n",
      "| 13|this movie stands...|    1|[this, movie, sta...|[movie, stands, e...|(500,[10,13,15,23...|(500,[10,13,15,23...|[-0.4581003447908...|[0.51497876703886...|       0.0|\n",
      "| 14|i was impressed w...|    1|[i, was, impresse...|[impressed, film,...|(500,[3,18,23,27,...|(500,[3,18,23,27,...|[-1.4101994978781...|[0.14713785192568...|       1.0|\n",
      "| 15|i consider myself...|    1|[i, consider, mys...|[consider, lucky,...|(500,[3,5,7,10,17...|(500,[3,5,7,10,17...|[-0.1968267633855...|[0.62945489528305...|       0.0|\n",
      "| 16|rita hayworth as ...|    1|[rita, hayworth, ...|[rita, hayworth, ...|(500,[0,1,3,4,5,6...|(500,[0,1,3,4,5,6...|[-4.4513307025676...|[2.84027070078451...|       1.0|\n",
      "| 17|i had the good fo...|    1|[i, had, the, goo...|[good, fortune, p...|(500,[7,13,15,25,...|(500,[7,13,15,25,...|[-1.4931048426933...|[0.12080236139725...|       1.0|\n",
      "| 18|i loved this film...|    1|[i, loved, this, ...|[loved, film!, gr...|(500,[3,5,6,9,11,...|(500,[3,5,6,9,11,...|[-5.9906511406371...|[1.62535204828558...|       1.0|\n",
      "| 19|people who say th...|    1|[people, who, say...|[people, say, loo...|(500,[5,13,15,18,...|(500,[5,13,15,18,...|[-0.3906914364593...|[0.55079925123315...|       0.0|\n",
      "| 20|this may be the m...|    1|[this, may, be, t...|[may, tension-fil...|(500,[0,3,7,11,12...|(500,[0,3,7,11,12...|[-1.7444277726577...|[0.07449005931989...|       1.0|\n",
      "| 21|i never saw docto...|    1|[i, never, saw, d...|[never, saw, doct...|(500,[3,4,5,9,10,...|(500,[3,4,5,9,10,...|[0.22217450481116...|[0.78997452409259...|       0.0|\n",
      "| 22|hilarious show wi...|    1|[hilarious, show,...|[hilarious, show,...|(500,[5,19,25,35,...|(500,[5,19,25,35,...|[-3.3905439027691...|[0.00319610647087...|       1.0|\n",
      "| 23|in following the ...|    1|[in, following, t...|[following, lines...|(500,[3,4,8,11,12...|(500,[3,4,8,11,12...|[-3.6477511315723...|[0.00156624070067...|       1.0|\n",
      "| 24|good movie, actin...|    1|[good, movie,, ac...|[good, movie,, ac...|(500,[3,7,8,9,10,...|(500,[3,7,8,9,10,...|[-1.5107462812301...|[0.09349599589033...|       1.0|\n",
      "| 25|what makes this o...|    1|[what, makes, thi...|[makes, one, bett...|(500,[3,19,44,60,...|(500,[3,19,44,60,...|[0.58773407263136...|[0.89472217016029...|       0.0|\n",
      "| 26|writer/director j...|    1|[writer/director,...|[writer/director,...|(500,[3,10,13,21,...|(500,[3,10,13,21,...|[-0.7916660093254...|[0.33523071355803...|       1.0|\n",
      "| 27|kon ichikawa had ...|    1|[kon, ichikawa, h...|[kon, ichikawa, l...|(500,[0,1,2,3,5,6...|(500,[0,1,2,3,5,6...|[0.97768058029033...|[0.94454206455143...|       0.0|\n",
      "| 28|i loved this movi...|    1|[i, loved, this, ...|[loved, movie, -,...|(500,[14,50,62,64...|(500,[14,50,62,64...|[-2.9865040311915...|[0.00649139687814...|       1.0|\n",
      "| 29|having watched th...|    1|[having, watched,...|[watched, show, f...|(500,[12,15,18,19...|(500,[12,15,18,19...|[0.59251362672593...|[0.88934375124057...|       0.0|\n",
      "| 30|i am profoundly g...|    1|[i, am, profoundl...|[profoundly, grat...|(500,[10,13,15,17...|(500,[10,13,15,17...|[0.58638682039231...|[0.90325006086082...|       0.0|\n",
      "| 31|this second pairi...|    1|[this, second, pa...|[second, pairing,...|(500,[13,14,15,24...|(500,[13,14,15,24...|[-2.1923440167791...|[0.03139690317981...|       1.0|\n",
      "| 32|who won the best ...|    1|[who, won, the, b...|[won, best, actre...|(500,[0,3,5,8,11,...|(500,[0,3,5,8,11,...|[-2.6433951931160...|[0.01224653871895...|       1.0|\n",
      "| 33|each guy liv tyle...|    1|[each, guy, liv, ...|[guy, liv, tyler,...|(500,[11,15,61,64...|(500,[11,15,61,64...|[-0.6684601188403...|[0.42270317160156...|       1.0|\n",
      "| 34|there was talk on...|    1|[there, was, talk...|[talk, e!, hollyw...|(500,[0,3,6,7,10,...|(500,[0,3,6,7,10,...|[-1.5364140080150...|[0.10310590446595...|       1.0|\n",
      "| 35|pretty amusing sp...|    1|[pretty, amusing,...|[pretty, amusing,...|(500,[10,17,20,21...|(500,[10,17,20,21...|[-0.6705694881115...|[0.40188455637850...|       1.0|\n",
      "| 36|when i was younge...|    1|[when, i, was, yo...|[younger,, movie,...|(500,[1,4,5,13,24...|(500,[1,4,5,13,24...|[-1.7941237900088...|[0.07582096310992...|       1.0|\n",
      "| 37|well groomed, wel...|    1|[well, groomed,, ...|[well, groomed,, ...|(500,[3,4,23,40,4...|(500,[3,4,23,40,4...|[-0.7037519632434...|[0.36256678350979...|       1.0|\n",
      "| 38|this is film is p...|    1|[this, is, film, ...|[film, probably, ...|(500,[3,8,10,13,2...|(500,[3,8,10,13,2...|[-2.4200970680709...|[0.01843986359548...|       1.0|\n",
      "| 39|a wounded tonto s...|    1|[a, wounded, tont...|[wounded, tonto, ...|(500,[18,24,46,57...|(500,[18,24,46,57...|[0.87769298100880...|[0.93887270290756...|       0.0|\n",
      "| 40|everyone is a gen...|    1|[everyone, is, a,...|[everyone, genius...|(500,[4,15,17,19,...|(500,[4,15,17,19,...|[-1.0344804188245...|[0.23430332570793...|       1.0|\n",
      "| 41|this show was inc...|    1|[this, show, was,...|[show, incredible...|(500,[4,15,19,57,...|(500,[4,15,19,57,...|[-2.7829978452968...|[0.01068660751844...|       1.0|\n",
      "| 42|the best british ...|    1|[the, best, briti...|[best, british, c...|(500,[0,3,8,14,19...|(500,[0,3,8,14,19...|[-1.9531582529106...|[0.04925711073697...|       1.0|\n",
      "| 43|being of cephallo...|    1|[being, of, cepha...|[cephallonian, de...|(500,[6,59,60,63,...|(500,[6,59,60,63,...|[-1.8164839360691...|[0.06374926958193...|       1.0|\n",
      "| 44|many films attemp...|    1|[many, films, att...|[many, films, att...|(500,[1,3,4,5,10,...|(500,[1,3,4,5,10,...|[-3.4395008026700...|[0.00321983895347...|       1.0|\n",
      "| 45|out to sea was a ...|    1|[out, to, sea, wa...|[sea, great, movi...|(500,[1,3,48,81,9...|(500,[1,3,48,81,9...|[-3.4797890720781...|[0.00277076320392...|       1.0|\n",
      "| 46|isabel has just g...|    1|[isabel, has, jus...|[isabel, gone, ja...|(500,[3,7,15,17,1...|(500,[3,7,15,17,1...|[-1.6527884715351...|[0.08208756275095...|       1.0|\n",
      "| 47|b.b. thornton pro...|    1|[b.b., thornton, ...|[b.b., thornton, ...|(500,[12,44,54,66...|(500,[12,44,54,66...|[-1.0502774040039...|[0.21930010233499...|       1.0|\n",
      "| 48|i just discovered...|    1|[i, just, discove...|[discovered, film...|(500,[0,3,5,10,13...|(500,[0,3,5,10,13...|[-2.8379080601457...|[0.00893416438312...|       1.0|\n",
      "| 49|i just checked ou...|    1|[i, just, checked...|[checked, northan...|(500,[3,6,10,15,1...|(500,[3,6,10,15,1...|[-2.2625441304418...|[0.02536052807946...|       1.0|\n",
      "+---+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_after_transform.show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "      Tạo đối tượng Evaluator có sẵn trong Spark MLLib, đánh giá model\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T08:01:55.111053Z",
     "start_time": "2019-11-11T08:00:20.951806Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "result = evaluator.evaluate(data_after_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "      In ra kết quả đánh giá là độ chính xác, có thể áp dụng nhiều thông số đánh giá khác. Tham khảo thêm tại:\n",
    "    </p>\n",
    "    <p>\n",
    "        <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\">https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier</a>\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T08:02:54.455828Z",
     "start_time": "2019-11-11T08:02:54.372321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6917951668550886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Kết Thúc một phiên làm việc trong Spark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T08:03:25.929812Z",
     "start_time": "2019-11-11T08:03:25.511975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_of_code\n"
     ]
    }
   ],
   "source": [
    "print(\"end_of_code\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
