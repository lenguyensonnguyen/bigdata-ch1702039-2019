{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <p>\n",
    "        MÔN BIG DATA 2019\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Nhóm 13\n",
    "    </p>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    <p>\n",
    "        SỬ DỤNG SPARK VÀ SPARK MACHINE LEARNING LIBRARY ĐỂ TRAIN MODEL PHÂN TÍCH NGỮ NGHĨA DÙNG MULTILAYER PERCEPTRONS (BASIC DEEP LEARNING)\n",
    "    </p>\n",
    "    <p style=\"color: blue\">\n",
    "        Phần đánh giá (Evaluation) Model đã train\n",
    "    </p>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo các biến môi trường để Spark sử dụng trong quá trình chạy\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/spark/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color: blue\">\n",
    "        Dùng gói findSpark để khởi tạo môi trường chạy\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Import các thư viện của PySpark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo số memory mà mỗi Worker sẽ sử dụng để thực thi task\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '6656m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Khai báo địa chỉ của Spark master, lưu ý là phải thay đổi địa chỉ cho phù hợp với từng Spark cluster\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo spark context, lưu ý nhớ thay đổi lại địa chỉ của spark cho phù hợp\n",
    "sc = SparkContext(\"spark://10.255.255.6:7077\", \"Sematic Analysic Evaluation\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khai báo một số hằng số\n",
    "NUMBER_INSTANCE_FOR_PC = 12500\n",
    "# NUMBER_FEATURE_VECTOR = 500\n",
    "# đường dẫn đến tập train positive\n",
    "TEST_PATH_POS = \"./semantic_data/aclImdb/test/pos/\"\n",
    "# đường dẫn đến tập train negative\n",
    "TEST_PATH_NEG = \"./semantic_data/aclImdb/test/neg/\"\n",
    "# biến lưu dữ liệu train cả positive và negative\n",
    "data_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Dữ liệu test cũng có 2 tập:\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Positive: nhận xét tích cực, chứa các câu nhận xét mang ý nghĩa tích cực, sẽ được đánh label là 1\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Negative: nhận xét tiêu cực, chứa các câu nhận xét mang ý nghĩa tiêu cực, sẽ được đánh label là 0\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-28T07:45:32.767810Z",
     "start_time": "2019-10-28T07:45:32.699757Z"
    }
   },
   "outputs": [],
   "source": [
    "# đọc dữ liệu của data train positive\n",
    "listfile_pos = listdir(TEST_PATH_POS)\n",
    "listfile_pos = enumerate(listfile_pos)\n",
    "counter = 1\n",
    "for index, file_pos in listfile_pos:\n",
    "    try:\n",
    "        with open(TEST_PATH_POS + file_pos, 'r') as f_pos:\n",
    "            noidung = f_pos.read()\n",
    "            noidung = noidung.lower()\n",
    "            # đánh label cho tập data train positive là 1\n",
    "            data_test.append((index, noidung, 1))\n",
    "        if counter >= NUMBER_INSTANCE_FOR_PC:\n",
    "            break\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy dữ liệu cho tập data train negative\n",
    "listfile_neg = listdir(TEST_PATH_NEG)\n",
    "listfile_neg = enumerate(listfile_neg)\n",
    "counter = 1\n",
    "for index, file_neg in listfile_neg:\n",
    "    try:\n",
    "        with open(TEST_PATH_NEG + file_neg) as f_neg:\n",
    "            noidung_neg = f_neg.read()\n",
    "            noidung_neg = noidung_neg.lower()\n",
    "            # đánh label cho data train negative là 0\n",
    "            data_test.append((index, noidung_neg, 0))\n",
    "            if counter >= NUMBER_INSTANCE_FOR_PC:\n",
    "                break\n",
    "            else:\n",
    "                counter = counter + 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Tạo đối tượng DataFrame trong Spark để chứa dữ liệu train, đây là kiểu dữ liệu chuẩn trong việc xử lý phân tán và có thể thao tác dưới dạng SQL, lúc này dữ liệu train đã ở dạng phân tán khắp cluster\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo DataFrame trong Spark\n",
    "sentenceDataFrame_test = spark.createDataFrame(data_test, [\"id\", \"sentence\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, sentence: string, label: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceDataFrame_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "      Sử dụng lại model đã lưu thì dùng lệnh dưới đây\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = PipelineModel.load(\"hdfs://s14e18f4e58324b66b78ecd8c831a0c6413-master.uitlab.com:9000/sparkdata/pl2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "      Dùng model đã train áp dụng (transform) lên dữ liệu test đã tạo\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_after_transform = pl_model.transform(sentenceDataFrame_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "      Tạo đối tượng Evaluator có sẵn trong Spark MLLib, đánh giá model\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()\n",
    "result = evaluator.evaluate(data_after_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "      In ra kết quả đánh giá là độ chính xác, có thể áp dụng nhiều thông số đánh giá khác. Tham khảo thêm tại:\n",
    "    </p>\n",
    "    <p>\n",
    "        <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\">https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier</a>\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701253826967279"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Kết Thúc một phiên làm việc trong Spark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_of_code\n"
     ]
    }
   ],
   "source": [
    "print(\"end_of_code\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
