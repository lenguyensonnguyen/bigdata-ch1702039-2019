{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>\n",
    "    <p>\n",
    "        MÔN BIG DATA 2019\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Nhóm 13\n",
    "    </p>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "    <p>\n",
    "        SỬ DỤNG SPARK VÀ SPARK MACHINE LEARNING LIBRARY ĐỂ TRAIN MODEL PHÂN TÍCH NGỮ NGHĨA DÙNG MULTILAYER PERCEPTRONS (BASIC DEEP LEARNING)\n",
    "    </p>\n",
    "    <p style=\"color: blue\">\n",
    "        Phần áp dụng Model đã train vào phân tích dữ liệu Real Time sử dụng Kafka\n",
    "    </p>\n",
    "     <img src=\"https://lh3.googleusercontent.com/bp9_jpWQssGTk3VzLFlywR8jDNlyGWYc-9vIDTb1-1ovsTQzfMPhTbwrZv12n1YAAbtW4s5eYc-pxOXgfYyX3w7cseef_IsmVAjc_j2VRvv3aCrKQFSdA_v3YpTQyxwBtPgh0IpJWMFe9boJ2tULIzlAT18bXCJN2IGQ-gXZkfEG0_HtV6-oN4l7qahMhZpCcE4N8AX048YRWWyLZAPFprvtRiebkJHRv5aLk1zNqkZP3fxTu67ltR148Tm2NoEl6OS_DanNwgHEHVbI3aXmoy0uVlI6d6t1sTtcq7oGuNfmXM04Eftu_VKe46wBsBrQ0lSLn6JPnzU0t0krEGwJ5fbDMD1-qo0wStiz4i2Tr9ivgUVRSwqPBXW-WtKli6qcZW-PfDJg2Gga84qL2pZ5uEG5wjLuP0_FqcwC_Ngt-e2nwXCa7QQ-Uxh7oSD3zpu2unlIHfufExxnOc5Ub8CdlhLRmnQdOVE-R6rMon1s8iwNBvr6yTaOCXkaxltzomnDh0Y09G3sGTMTz_FHkjBxdjv3STRAt7T4QmqxvA9HyyzoTGZhGhMF4sCfLU7PM-HmcLQGCgWdAOTaIgBmfJw099QWckc7wnqHFR8KAHC1bIFDn2yCPomnZjO2cpmL4K1KmQGlzvTM40f1ynw7DhzF6KoT_ucbFn2t6KUOLjLAACTLdoKCmSG4cUU=w1885-h899-no\" alt=\"\" height=\"100%\" width=\"100%\"> \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Khai báo các biến môi trường để Spark sử dụng trong quá trình chạy\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/spark/spark-2.4.3-bin-hadoop2.7\"\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local --packages org.apache.spark:spark-streaming-kafka-0-8:2.3.0 pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Import các thư viện của PySpark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Khai báo số memory mà mỗi Worker sẽ sử dụng để thực thi task\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '6656m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Khai báo địa chỉ của Spark master, lưu ý là phải thay đổi địa chỉ cho phù hợp với từng Spark cluster\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo spark context, lưu ý nhớ thay đổi lại địa chỉ của spark cho phù hợp\n",
    "sc = SparkContext(\"spark://10.255.255.6:7077\", \"Kafka Semantic Handle Real Time\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "      Sử dụng lại model (Load Model) đã lưu sử dụng lệnh dưới đây\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_49b6081081c8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_model = PipelineModel.load(\"hdfs://s14e18f4e58324b66b78ecd8c831a0c6413-master.uitlab.com:9000/sparkdata/pl2.model\")\n",
    "pl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Import các thư viện của PySpark Streaming và Kafka sử dụng trong Spark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Khai báo địa chỉ của Kafka Cluster và topic để lấy dữ liệu\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafkaBroker = 'localhost:9092'\n",
    "topic = 'spark-sematic-input1'\n",
    "batchTimeDur = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Tạo đối tượng Streaming, với Time là 1s sẽ fetch dữ liệu một lần\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, batchTimeDur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Tạo luồng Streaming Kafka ứng với Spark Context và Topic đã khai báo\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "directKafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\"metadata.broker.list\": kafkaBroker})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Import thư viện xử lý Kafka\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Tạo Kafka Producer để đẩy dữ liệu sau khi đã đi qua Model Deep Learning quay ngược trở về Kafka, cung cấp dữ liệu cho các nguồn khác.\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:red\">\n",
    "        Function để xử lý dữ liệu trong Streaming\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(message):\n",
    "    records = message.collect()\n",
    "    data = []\n",
    "    index = 1\n",
    "    for record in records:\n",
    "        key, value = record\n",
    "        #print(value)\n",
    "        data.append((index, value))\n",
    "        index = index + 1\n",
    "    if len(data) > 0:\n",
    "        #print(data)\n",
    "        sentenceDataFrame = spark.createDataFrame(data, [\"id\", \"sentence\"])\n",
    "        new_dt = pl_model.transform(sentenceDataFrame)\n",
    "        new_dt = new_dt.select(\"sentence\", \"prediction\").collect()\n",
    "        \n",
    "        for row in new_dt:\n",
    "            s = row['sentence']\n",
    "            p = row['prediction']\n",
    "            \n",
    "            o = {\n",
    "                'sentence': s,\n",
    "                'prediction': p\n",
    "            }\n",
    "            \n",
    "            j = json.dumps(o)\n",
    "            \n",
    "            print(j)\n",
    "            \n",
    "            j = str.encode(j)\n",
    "            \n",
    "            producer.send(\"spark-sematic-output1\", j)\n",
    "            producer.flush()\n",
    "            \n",
    "            #print(j)\n",
    "            \n",
    "        \n",
    "        #print(new_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Đăng ký funtion cho luồng Kafka Streaming\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "directKafkaStream.foreachRDD(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p style=\"color:blue\">\n",
    "        Start Streaming và xem kết quả.\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Mỗi khi có luồng dữ liệu đến, data sẽ chạy qua model để được giá trị prediction.\n",
    "    </p>\n",
    "    <p style=\"color:red\">\n",
    "        Sau khi có kết quả, data kết quả sẽ được submit lên một topic Kafka mới, Topic output này sẽ là nguồn dữ liệu cho việc lưu trữ xuống MongoDB hoặc được hiển thị lên biểu đồ dạng Real Time.\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prediction\": 1.0, \"sentence\": \"This is a pale imitation of 'Officer and a Gentleman.' There is NO chemistry between Kutcher and the unknown woman who plays his love interest. The dialog is wooden, the situations hackneyed. It's too long and the climax is anti-climactic(!). I love the USCG, its men and women are fearless and tough. The action scenes are awesome, but this movie doesn't do much for recruiting, I fear. The script is formulaic, but confusing. Kutcher's character is trying to redeem himself for an accident that wasn't his fault? Costner's is raging against the dying of the light, but why? His 'conflict' with his wife is about as deep as a mud puddle. I saw this sneak preview for free and certainly felt I got my money's worth.\"}\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>\n",
    "    <p>\n",
    "        Kết Thúc một phiên làm việc trong Spark\n",
    "    </p>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end_of_code\n"
     ]
    }
   ],
   "source": [
    "print(\"end_of_code\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
